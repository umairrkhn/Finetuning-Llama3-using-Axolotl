{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKL19IgoiGL5",
        "outputId": "bcf0bb06-b761-4411-b7ae-ec018cea488f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'axolotl' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j83JctjIjcLd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd axolotl\n",
        "!pip install -e '.[flash-attn,deepspeed]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvUf1Ih3jkNR"
      },
      "outputs": [],
      "source": [
        "# restart the runtime in order to use newly installed versions\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "J4tlSSStjusA"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Your YAML string\n",
        "yaml_string = \"\"\"\n",
        "base_model: NousResearch/Llama-3.2-1B\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "\n",
        "load_in_8bit: false\n",
        "load_in_4bit: true\n",
        "strict: false\n",
        "\n",
        "datasets:\n",
        "  - path: nldemo/story-summarization-demo\n",
        "    type: alpaca\n",
        "    ds_type: parquet\n",
        "dataset_prepared_path:\n",
        "output_dir: ./outputs/qlora-out\n",
        "\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "\n",
        "sequence_len: 4096\n",
        "sample_packing: true\n",
        "eval_sample_packing: false\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "gradient_accumulation_steps: 4\n",
        "micro_batch_size: 2\n",
        "num_epochs: 4\n",
        "optimizer: paged_adamw_32bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: auto\n",
        "fp16:\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: false\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch: 4\n",
        "saves_per_epoch: 1\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: <|finetune_right_pad_id|>\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(yaml_string)\n",
        "\n",
        "# Specify your file path\n",
        "file_path = 'test_axolotl.yaml'\n",
        "\n",
        "# Write the YAML file\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b6pkHYLo3LY"
      },
      "outputs": [],
      "source": [
        "# By using the ! the comand will be executed as a bash command\n",
        "!accelerate launch -m axolotl.cli.train /content/axolotl/test_axolotl.yaml --sample_packing=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC4xKkdYpBHe"
      },
      "outputs": [],
      "source": [
        "# By using the ! the comand will be executed as a bash command\n",
        "!accelerate launch -m axolotl.cli.inference /content/axolotl/test_axolotl.yaml \\\n",
        "    --qlora_model_dir=\"./outputs/qlora-out\" --gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y-_dJ8xMYCF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
